{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple linear regression with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create functions that we will use in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import modules\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "create global variable of weights and bias\n",
    "'''\n",
    "W = tf.Variable(tf.zeros([2, 1]), name = 'weights')\n",
    "b = tf.Variable(0., name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "create inference function\n",
    "'''\n",
    "def inference(X):\n",
    "    return tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "loss function, MSE\n",
    "'''\n",
    "def loss(X, y):\n",
    "    y_predicted = tf.transpose(inference(X)) #remember to transpos\n",
    "    return tf.reduce_sum(tf.squared_difference(y, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train function\n",
    "'''\n",
    "def train(total_loss):\n",
    "    learning_rate = 0.000001\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "evaluate\n",
    "'''\n",
    "def evaluate(sess, X, y):\n",
    "    print(sess.run(inference([[50., 20.]]))) # ~ 303\n",
    "    print(sess.run(inference([[50., 70.]]))) # ~ 256\n",
    "    print(sess.run(inference([[90., 20.]]))) # ~ 303\n",
    "    print(sess.run(inference([[90., 70.]]))) # ~ 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create a session to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/10000, total_loss: 1230281.75\n",
      "epoch: 100/10000, total_loss: 62959.94921875\n",
      "epoch: 200/10000, total_loss: 52061.58984375\n",
      "epoch: 300/10000, total_loss: 48652.8203125\n",
      "epoch: 400/10000, total_loss: 47586.0390625\n",
      "epoch: 500/10000, total_loss: 47251.62109375\n",
      "epoch: 600/10000, total_loss: 47146.20703125\n",
      "epoch: 700/10000, total_loss: 47112.40234375\n",
      "epoch: 800/10000, total_loss: 47101.01171875\n",
      "epoch: 900/10000, total_loss: 47096.60546875\n",
      "epoch: 1000/10000, total_loss: 47094.40234375\n",
      "epoch: 1100/10000, total_loss: 47092.87890625\n",
      "epoch: 1200/10000, total_loss: 47091.5625\n",
      "epoch: 1300/10000, total_loss: 47090.32421875\n",
      "epoch: 1400/10000, total_loss: 47089.1015625\n",
      "epoch: 1500/10000, total_loss: 47087.88671875\n",
      "epoch: 1600/10000, total_loss: 47086.67578125\n",
      "epoch: 1700/10000, total_loss: 47085.44921875\n",
      "epoch: 1800/10000, total_loss: 47084.2421875\n",
      "epoch: 1900/10000, total_loss: 47083.03515625\n",
      "epoch: 2000/10000, total_loss: 47081.828125\n",
      "epoch: 2100/10000, total_loss: 47080.62109375\n",
      "epoch: 2200/10000, total_loss: 47079.40625\n",
      "epoch: 2300/10000, total_loss: 47078.19921875\n",
      "epoch: 2400/10000, total_loss: 47076.99609375\n",
      "epoch: 2500/10000, total_loss: 47075.78125\n",
      "epoch: 2600/10000, total_loss: 47074.5625\n",
      "epoch: 2700/10000, total_loss: 47073.36328125\n",
      "epoch: 2800/10000, total_loss: 47072.16015625\n",
      "epoch: 2900/10000, total_loss: 47070.94921875\n",
      "epoch: 3000/10000, total_loss: 47069.74609375\n",
      "epoch: 3100/10000, total_loss: 47068.546875\n",
      "epoch: 3200/10000, total_loss: 47067.32421875\n",
      "epoch: 3300/10000, total_loss: 47066.12109375\n",
      "epoch: 3400/10000, total_loss: 47064.9140625\n",
      "epoch: 3500/10000, total_loss: 47063.7109375\n",
      "epoch: 3600/10000, total_loss: 47062.51171875\n",
      "epoch: 3700/10000, total_loss: 47061.3046875\n",
      "epoch: 3800/10000, total_loss: 47060.10546875\n",
      "epoch: 3900/10000, total_loss: 47058.88671875\n",
      "epoch: 4000/10000, total_loss: 47057.6953125\n",
      "epoch: 4100/10000, total_loss: 47056.484375\n",
      "epoch: 4200/10000, total_loss: 47055.2890625\n",
      "epoch: 4300/10000, total_loss: 47054.078125\n",
      "epoch: 4400/10000, total_loss: 47052.875\n",
      "epoch: 4500/10000, total_loss: 47051.671875\n",
      "epoch: 4600/10000, total_loss: 47050.4765625\n",
      "epoch: 4700/10000, total_loss: 47049.26953125\n",
      "epoch: 4800/10000, total_loss: 47048.07421875\n",
      "epoch: 4900/10000, total_loss: 47046.8671875\n",
      "epoch: 5000/10000, total_loss: 47045.66015625\n",
      "epoch: 5100/10000, total_loss: 47044.4765625\n",
      "epoch: 5200/10000, total_loss: 47043.27734375\n",
      "epoch: 5300/10000, total_loss: 47042.06640625\n",
      "epoch: 5400/10000, total_loss: 47040.87109375\n",
      "epoch: 5500/10000, total_loss: 47039.66015625\n",
      "epoch: 5600/10000, total_loss: 47038.48046875\n",
      "epoch: 5700/10000, total_loss: 47037.27734375\n",
      "epoch: 5800/10000, total_loss: 47036.0703125\n",
      "epoch: 5900/10000, total_loss: 47034.875\n",
      "epoch: 6000/10000, total_loss: 47033.69140625\n",
      "epoch: 6100/10000, total_loss: 47032.48828125\n",
      "epoch: 6200/10000, total_loss: 47031.29296875\n",
      "epoch: 6300/10000, total_loss: 47030.1015625\n",
      "epoch: 6400/10000, total_loss: 47028.8984375\n",
      "epoch: 6500/10000, total_loss: 47027.703125\n",
      "epoch: 6600/10000, total_loss: 47026.50390625\n",
      "epoch: 6700/10000, total_loss: 47025.3203125\n",
      "epoch: 6800/10000, total_loss: 47024.125\n",
      "epoch: 6900/10000, total_loss: 47022.92578125\n",
      "epoch: 7000/10000, total_loss: 47021.734375\n",
      "epoch: 7100/10000, total_loss: 47020.546875\n",
      "epoch: 7200/10000, total_loss: 47019.3515625\n",
      "epoch: 7300/10000, total_loss: 47018.15625\n",
      "epoch: 7400/10000, total_loss: 47016.9609375\n",
      "epoch: 7500/10000, total_loss: 47015.7734375\n",
      "epoch: 7600/10000, total_loss: 47014.58203125\n",
      "epoch: 7700/10000, total_loss: 47013.38671875\n",
      "epoch: 7800/10000, total_loss: 47012.1953125\n",
      "epoch: 7900/10000, total_loss: 47011.01171875\n",
      "epoch: 8000/10000, total_loss: 47009.82421875\n",
      "epoch: 8100/10000, total_loss: 47008.62890625\n",
      "epoch: 8200/10000, total_loss: 47007.4375\n",
      "epoch: 8300/10000, total_loss: 47006.2578125\n",
      "epoch: 8400/10000, total_loss: 47005.07421875\n",
      "epoch: 8500/10000, total_loss: 47003.87890625\n",
      "epoch: 8600/10000, total_loss: 47002.6796875\n",
      "epoch: 8700/10000, total_loss: 47001.49609375\n",
      "epoch: 8800/10000, total_loss: 47000.31640625\n",
      "epoch: 8900/10000, total_loss: 46999.1171875\n",
      "epoch: 9000/10000, total_loss: 46997.9375\n",
      "epoch: 9100/10000, total_loss: 46996.75\n",
      "epoch: 9200/10000, total_loss: 46995.5703125\n",
      "epoch: 9300/10000, total_loss: 46994.3828125\n",
      "epoch: 9400/10000, total_loss: 46993.1875\n",
      "epoch: 9500/10000, total_loss: 46992.00390625\n",
      "epoch: 9600/10000, total_loss: 46990.828125\n",
      "epoch: 9700/10000, total_loss: 46989.625\n",
      "epoch: 9800/10000, total_loss: 46988.45703125\n",
      "epoch: 9900/10000, total_loss: 46987.2734375\n",
      "----------------------------------\n",
      "final model, weights: [[ 1.2922349 ]\n",
      " [ 5.58937836]], bias: 1.1374355554580688\n",
      "----------------------------------\n",
      "[[ 177.53675842]]\n",
      "[[ 457.00564575]]\n",
      "[[ 229.22615051]]\n",
      "[[ 508.69503784]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #run variable initializer\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    #get the inputs\n",
    "    X, y = inputs()\n",
    "    \n",
    "    #get the total loss\n",
    "    total_loss = loss(X, y)\n",
    "    \n",
    "    #create train function\n",
    "    train_func = train(total_loss)\n",
    "    \n",
    "    epochs = 10000\n",
    "    for epoch in range(epochs):\n",
    "        sess.run([train_func])\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(\"epoch: {}/{}, total_loss: {}\".format(epoch, epochs, sess.run(total_loss)))\n",
    "            \n",
    "    print('----------------------------------')\n",
    "    print(\"final model, weights: {}, bias: {}\".format(sess.run(W), sess.run(b)))\n",
    "    print('----------------------------------')\n",
    "    evaluate(sess, X, y)\n",
    "    \n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
